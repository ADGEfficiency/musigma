
## 2019-08-21, Wednesday

### Paper
Hodges, J. S. (2019). Statistical methods research done as science rather than mathematics. *arXiv preprint arXiv:1905.08381*.

### Protocol

(protocol is rather short and cumbersome, since we all were into discussion)

* Is it really so that there is almost no empirical studies of such popular instruments like logistic and Cox regression?
    * Probably there are, but he puts higher standards for "empirical studies"

* One of the main problem with these studies that they strive to provide only one number

Discussion
* (Other) such studies look at models just as black box.
* Author takes part of the model and tries to understand it (without simplification and simulation), in order to understand what is "really going on"
* Contra-argument: Treating your model as a black box VS => Different kind of the hypotheses you can test!
    * By focusing only on the "proovable", these math people miss a lot of insight that are much relevant 

* In ML: They have some toy sets (huge repos with ~50 sets), take a new model idea, and proof that they are good on these 50 sets. 
* Contra-argument: IN this case you are showing that YOUR black box is better than others, but NOT why the black box X was better black box Y. 
* (more detailed discussion regarding the points above, i.e. in regard to random forest, convolutional networks)
* Also, different statistical methods (or even clusters of methods) are more or less suitable to be tested under the paradigm stated in the paper.

Quote of the day: "ML is throwing computational power to work until it can recognize a cat"

* "Drill" example
    * Suppose a drill doesn't work - how would you act to find out what's wrong?
 
